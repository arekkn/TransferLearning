{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "Collecting tf-nightly\n",
      "  Downloading tf_nightly-2.10.0.dev20220521-cp38-cp38-win_amd64.whl (359.4 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (1.22.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (1.14.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (14.0.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (1.16.0)\n",
      "Collecting keras-nightly~=2.10.0.dev\n",
      "  Downloading keras_nightly-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (1.0.0)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (56.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (0.26.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (1.1.2)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting tf-estimator-nightly~=2.10.0.dev\n",
      "  Downloading tf_estimator_nightly-2.10.0.dev2022052308-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (1.46.3)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.6.0-cp38-cp38-win_amd64.whl (2.8 MB)\n",
      "Collecting tb-nightly~=2.10.0.a\n",
      "  Downloading tb_nightly-2.10.0a20220522-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tf-nightly) (4.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.6.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\macch\\desktop\\venv_transfer_learning\\lib\\site-packages (from packaging->tf-nightly) (3.0.8)\n",
      "Installing collected packages: protobuf, tf-estimator-nightly, tb-nightly, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tf-nightly\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-pasta-0.2.0 h5py-3.6.0 keras-nightly-2.10.0 protobuf-3.19.4 tb-nightly-2.10.0a20220522 tf-estimator-nightly-2.10.0.dev2022052308 tf-nightly-2.10.0.dev20220521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\macch\\desktop\\venv_transfer_learning\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.python_state has been moved to tensorflow.python.trackable.python_state. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') # training on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_blocks(student, teacher):\n",
    "    '''\n",
    "    Function used to get BasicBlocks from ResNet class model\n",
    "    '''\n",
    "    student_layers = [student.layer1, student.layer2, student.layer3, student.layer4]\n",
    "    teacher_layers = [teacher.layer1, teacher.layer2, teacher.layer3, teacher.layer4]\n",
    "\n",
    "    student_blocks = []\n",
    "    teacher_blocks = []\n",
    "    \n",
    "    for i in range(len(student_layers)):\n",
    "        teacher_blocks += list(np.array_split(teacher_layers[i], len(student_layers[i]))) # divide teacher blocks into n list, where n is number of student blocks\n",
    "        student_blocks += [el for el in student_layers[i]]\n",
    "\n",
    "    return student_blocks, teacher_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, student, teacher, a_all):\n",
    "    '''\n",
    "    Forward function for hybrid ResNet \n",
    "    '''\n",
    "    def _forward_blocks(x, student_blocks, teacher_blocks, a_all):\n",
    "        '''\n",
    "        Forward function containing only hybrid blocks predicitons\n",
    "        '''\n",
    "        len_teacher_blocks = len(teacher_blocks)\n",
    "        len_student_blocks = len(student_blocks)\n",
    "        assert len_teacher_blocks == len_student_blocks   # check if size of blocks is the same\n",
    "        tmp_x = x\n",
    "        for i in range(len_student_blocks): # hybrid block\n",
    "            if a_all[i] == 1: # student path\n",
    "                tmp_x = student_blocks[i].forward(tmp_x)\n",
    "\n",
    "            if a_all[i] == 0: # teacher path\n",
    "                for j in range(len(teacher_blocks[i])):\n",
    "                    tmp_x = teacher_blocks[i][j].forward(tmp_x)\n",
    "\n",
    "        return tmp_x, a_all\n",
    "\n",
    "    student_blocks, teacher_blocks = hybrid_blocks(student, teacher)\n",
    "    \n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    tmp_x = x     # forward pipeline\n",
    "    tmp_x = student.conv1(tmp_x)\n",
    "    tmp_x = student.bn1(tmp_x)\n",
    "    tmp_x = student.relu(tmp_x)\n",
    "    tmp_x = student.maxpool(tmp_x)\n",
    "    tmp_x, a_all = _forward_blocks(tmp_x, student_blocks, teacher_blocks, a_all)\n",
    "    tmp_x = student.avgpool(tmp_x)\n",
    "    tmp_x = torch.flatten(tmp_x, 1)\n",
    "    tmp_x = student.fc(tmp_x)\n",
    "    output = softmax(tmp_x)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(data, student, teacher, p, epochs = 200,intervals=200):\n",
    "    # dodałem parametr intervals:\n",
    "    # jeśli intervals = epochs     mamy Uniform schedule\n",
    "    # jesli intervals = 1          mamy Linear growth schedule\n",
    "    # jesli 1 < intervals < epochs mamy Review schedule, gdzie intervals oznacza liczbę \"powtórek\"\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.Adam(student.parameters(), lr=0.001)\n",
    "    #optimizer(SGD) i modyfikacja learning rate(MultiStepLR) z artykułu\n",
    "    optimizer = optim.SGD(student.parameters(), lr=0.1, weight_decay=0.0001, momentum=0.9)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[100,150], gamma=0.1)\n",
    "    train_loss = []\n",
    "    train_score = []\n",
    "    x=np.linspace(p, 1, int(epochs/intervals))\n",
    "    print(f\"x = {x}\")\n",
    "    p_all=np.tile(x,intervals)\n",
    "    print(f\"p_all = {p_all}\")\n",
    "    for e in range(epochs):\n",
    "        print(f\"\\nEpoch no. {e}\")\n",
    "        score = 0\n",
    "        loss = 0\n",
    "        student_blocks, teacher_blocks = hybrid_blocks(student, teacher)\n",
    "        #a_all = [np.random.binomial(1, p) for i in range(len(student_blocks))]\n",
    "        a_all = [np.random.binomial(1, p_all[e]) for i in range(len(student_blocks))]   # hybrid block building schema \n",
    "        print(f\"p_all[e] = {p_all[e]}\")\n",
    "        print(f\"a_all = {a_all}\")\n",
    "        #a_all =[1,0,1,1,1,1,1,1]\n",
    "        for block, a in zip(student_blocks,a_all):\n",
    "            if a==0:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad=False\n",
    "            else:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad=True      \n",
    "        for image, label in data:\n",
    "            student_blocks, teacher_blocks = hybrid_blocks(student, teacher)\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = forward(image, student, teacher, a_all)\n",
    "            loss = loss_function(y_pred, label)         \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            val, index_ = torch.max(y_pred, axis=1)\n",
    "            score += torch.sum(index_ == label.data).item()\n",
    "            loss += loss.item()\n",
    "        scheduler.step()\n",
    "            \n",
    "        epoch_score = score / len(data)\n",
    "        epoch_loss = loss / len(data)\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_score.append(epoch_score)\n",
    "        print(\"Training loss: {}, accuracy: {}\".format(epoch_loss, epoch_score))\n",
    "        return train_loss, train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34 = models.resnet34(pretrained=True)\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc =  nn.Linear(512, 2)\n",
    "resnet34.fc = nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\n",
      "x = [0.8]\n",
      "p_all = [0.8 0.8 0.8 0.8 0.8 0.8]\n",
      "\n",
      "Epoch no. 0\n",
      "p_all[e] = 0.8\n",
      "a_all = [0, 1, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\\n\") \n",
    "training(trainloader, resnet18, resnet34, 0.8,epochs=6,intervals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
